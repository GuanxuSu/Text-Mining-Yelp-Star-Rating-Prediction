{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Yelp Star Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Introduction\n",
    "More than ever before, people’s decisions of what to eat or where to go are subject to other’s opinions. The internet has become the ultimate trove of the opinions of many people. Today, websites like Yelp have turned to a vast database for places and restaurants that include reviews and opinions written by customers. This crowdsourcing method of extracting satisfaction has succeeded in providing different opinions about a certain restaurant.\n",
    "\n",
    "This project mainly aims at **finding out what makes a review positive or negative** and **predicting the ratings of reviews based on the text and a small set of relevant attributes**.\n",
    "\n",
    "From our research, we find that words with sentiment orientation play an important role in predicting star ratings. Moreover, it is easier to distinguish positive(3-5 stars) reviews from negative ones (1-2 star(s)) than telling the specific star rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Preparation\n",
    "For our experiments, we used a subset of Yelp reviews, which includes about 1.5 million entries. These data provide useful information such as business profile, review text, date of review etc. One example looks like:\n",
    "\n",
    "**Varaible**|Value|\n",
    ":-----:|:-----:\n",
    "**Stars**|5| \n",
    "**Name**|Red Lobster| \n",
    "**Text**|I had the opportunity to try out the red lobste my server a jeanne and she is amazing loved her and the great service| \n",
    "**Date**|2/6/2014|  \n",
    "** ...**|...|\n",
    "\n",
    "\n",
    "#### 2.1 Sampling\n",
    "After some preliminary exploration and Figure 1, we find that there're a lot more positive reviews (4-5 stars) than negative (1-3 stars) reviews. To balance the class distribution as well as simplifying sample size, we randomly selected 100,000 reviews from each star rating with for further analysis. Also, the businesses that do not have 3 reviews or exists less than 14 days are excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"image/uneven.png\" width = \"300\" height = \"200\" alt=\"uneven\" align=center />\n",
       "<h6 align=\"center\"> Fig. 1. Star rating distribution before sampling </h6>                               "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"image/uneven.png\" width = \"300\" height = \"200\" alt=\"uneven\" align=center />\n",
    "<h6 align=\"center\"> Fig. 1. Star rating distribution before sampling </h6>                               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Data preprocessing\n",
    "First, we cleaned the review texts by removing punctuations, digits, extra whitespaces and transforming all letters to lower case. After that we performed spelling correction and lemmatization. \n",
    "\n",
    "Next we would like to take context into consideration. It can be misleading if we only focus on single word but ignore context. For example, we may extract positive information from the sentence \"I don't like it and I'm not happy.\" after tokenization. Meanwhile, it can convey totally opposite sentiments depending on different context, such as \"pretty good\" and \"pretty bad\", \"go back\" and \"never go back\". Thus, we took two steps to avoid interpreting out of context.\n",
    "* Change negation format to reserve the negative meaning before tokenizing. E.g. change \"don't like\" to \"not_like\" and treat it as a single word.\n",
    "* Transform common phrases together into one single word. E.g. \"highly recommended\" to \"highly_recommended\", \"reasonable price\" to \"reasonable_price\".\n",
    "\n",
    "This whole procedure is organized as in Figure 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"image/data_preprocess.png\" width = \"600\" height = \"600\" alt=\"preprocess\" align=center />\n",
       "<h6 align=\"center\"> Fig. 2.  Data Preprocess Flow </h6>                               "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"image/data_preprocess.png\" width = \"600\" height = \"600\" alt=\"preprocess\" align=center />\n",
    "<h6 align=\"center\"> Fig. 2.  Data Preprocess Flow </h6>                               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Feature Engineering\n",
    "\n",
    "There are 7 variables in the raw data set, such as business location, review date etc. However after further exploration, we decide to use review text as the predictor soly, because other variables don't contribute significantly to star ratings. Also, in common sense the star rating of a review depends mostly on the review content. Thus our feature engineering part is based on review text only.\n",
    "\n",
    "The raw text contains millions of unique words, however not all of them are useful for predicting star rating. We want to select most useful words and create representative features based on selected words. The next two sections give a detailed explanation of words selection and feature creation.\n",
    "\n",
    "#### 3.1 Words Selection\n",
    "\n",
    "The first question is what are useful words? Intuitively, \"great\" and \"worst\" are useful cause the former tend to appear more in high star rating reviews while the latter tend to appear more in low ones. As an opposite, \"food\" and \"service\" are useless since they seem to appear equally in each star rating. More generally, useful words are those with a significantly larger likelihood of appearing in certain star rating level than other levels, thus they have high ability to distinguish between different star ratings. \n",
    "\n",
    "The second question is the coverage percentage of useful words. If only 10% of reviews contain those words, our analysis may not generalize well. Thus during words selection we also keep an eye on coverage percentage. \n",
    "\n",
    "The following sections introduce two metrics we use to evaluate how \"useful\" a word is, and our selection result.\n",
    "\n",
    "##### 3.1.1 Inverse Docunment Frequency (IDF)\n",
    "\n",
    "The Inverse Document Frequency of a word measures how often it appear in a collection of reviews. The formula is as follows:\n",
    "\n",
    "$$ IDF(word) = \\frac{N}{n} ,$$ \n",
    "\n",
    "where $N$ is the total number of reviews, $n$ is the number of reviews containing the specific word. The larger IDF is, the fewer reviews contain the specific word. For example, words like \"food\", \"menu\", \"chicken\" and \"restaurant\" have low IDF. Words like \"thump\", \"cray\" and \"coho\" have high IDF.\n",
    "\n",
    "##### 3.1.2 Diversity\n",
    "\n",
    "The Diversity of a word measures its ability to distinguish between different star ratings. It is the unevenness of frequency among different star ratings. The formula is: \n",
    "\n",
    "$$Div(word) = \\frac{Standard Deviation}{Mean} ,$$\n",
    "\n",
    "where Mean and Standard Deviation are in terms of the word's frequency distribution in each level of star ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"image/diversity.png\" width = \"400\" height = \"300\" alt=\"diversity\" align=center />\n",
       "<h6 align=\"center\"> Fig. 3. Example of Diversity</h6>    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"image/diversity.png\" width = \"400\" height = \"300\" alt=\"diversity\" align=center />\n",
    "<h6 align=\"center\"> Fig. 3. Example of Diversity</h6>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure3 is an example of how diversity of each word is calculated. If a word has frequency, $f=(f_1,f_2,f_3,f_4,f_5)$ inside star 1 to star 5, respectively. Then the Diversity of this word is:\n",
    "$$Div=\\frac{\\sqrt{\\sum\\limits_{i=1}^5 (f_i-\\bar{f})^2}}{\\bar{f}}$$\n",
    "\n",
    "The word “minute” has higher frequency in negative reviews and lower frequency in positive reviews, hence it has a higher diversity than the word “food”, which has almost equal frequencies among 5 star ratings.\n",
    "\n",
    "For example, words like \"worst food poisoning\", \"worst customer service \" and \"minute\" have high diversity, whereas words like \"invite\", \"muscle\" and \"food\" have lower diversity.\n",
    "\n",
    "##### 3.1.3 Words Selection Result\n",
    "\n",
    "After we get two metrics in 3.1.1 and 3.1.2, we can draw the following plot. Each point represents a unique word. \n",
    "Synthesize the two questions mentioned above, we come up with the threshold indicated by the two red lines to split the figure into 4 parts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"image/diversity_idf.png\" width = \"500\" height = \"300\" alt=\"2-step model\" align=center />\n",
       "<h6 align=\"center\"> Fig. 4. Diversity vs IDF</h6>    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"image/diversity_idf.png\" width = \"500\" height = \"300\" alt=\"2-step model\" align=center />\n",
    "<h6 align=\"center\"> Fig. 4. Diversity vs IDF</h6>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider words in the bottom right part have high ability to distinguish different star ratings and appear in most reviews. This part contains 5814 unique words which cover 99.2% reviews.\n",
    "\n",
    "\n",
    "#### 3.2 Fearture Creation\n",
    "\n",
    "##### 3.2.1 Word Score\n",
    "\n",
    "To measure the polarity of a word, we introduce the ***word score***. Word score is the average star (after mean-subtraction and standardization) of all the reviews containing this word.\n",
    "\n",
    "The left image is the histogram of all the words in our train set. As we can see, most of the words are concentrated around 0, which does not provide much information about interpreting review stars. However, after selecting the 5814 bottom right words mentioned before, we see an obvious bimodal distribution. All the words are clearly divided into \"negative\" and \"positive\" parts. The plots prove that the words selection procedure helps to filter out useless words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"image/histograms.png\" width = \"600\" height = \"300\" alt=\"2-step model\" align=center />\n",
       "<h6 align=\"center\"> Fig. 5. Word score distribution before and after words selection</h6> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"image/histograms.png\" width = \"600\" height = \"300\" alt=\"2-step model\" align=center />\n",
    "<h6 align=\"center\"> Fig. 5. Word score distribution before and after words selection</h6> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.2 Extracted Features\n",
    "\n",
    "**Minimum, Average and Maximum Scores**\n",
    "\n",
    "Now that we have a score for each word, we are able to convert a review into an ordered score vector **Y**. Minimum value, mean value and maximum value can be extracted from **Y**.\n",
    "* All the three plots have an increasing trend \n",
    "* The average score can best distinguish star rating among the three.\n",
    "* The minimum score cannot well distinguish 4-star and 5-star, but has the ability to distinguish different stars in negative reviews.\n",
    "* The maximum score also has the ability to distinguish the star ratings, especially between 3 and 4 stars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"image/scores.png\" width = \"800\" height = \"300\" alt=\"2-step model\" align=center />\n",
       "<h6 align=\"center\"> Fig. 6. Boxplot of Min/Avg/Max scores under each star rating</h6> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"image/scores.png\" width = \"800\" height = \"300\" alt=\"2-step model\" align=center />\n",
    "<h6 align=\"center\"> Fig. 6. Boxplot of Min/Avg/Max scores under each star rating</h6> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Emotion Trend**\n",
    "\n",
    "The three features above do not take the order information into account. Consider the two reviews below:\n",
    "\n",
    "1) One star off because the <font color='blue'>**service is miss**</font> but their curry make up for everything else. Seriously <font color='red'>**the best curry**</font> in town.\n",
    "\n",
    "2) Ambience was <font color='red'>**awesome**</font> but service a <font color='blue'>**so terrible**</font>. We didn’t even get a chance to try anything except for our first round of drinks.\n",
    "\n",
    "Both of the reviews say something positive and something negative. However, the first is a 4-star review while the second review only has 2 star. It seems that people still feel okay if they say negative words at the beginning but turn to say something positive. However, if people say something positive but then turn to say negative words, they may not be happy. \n",
    "\n",
    "In order to deal with this case, we introduce a new feature ***emotion trend***. We already have the score vector **Y**. Denote the index vector as **X**. Then the emotion trend is calculated as the slope, $\\beta$, of the regression line of **Y** vs **X**. We further take a power transformation $\\tilde\\beta=sign(\\beta)\\sqrt{|\\beta|}$.\n",
    "\n",
    "There is an increasing trend of slope as star rating goes up. Furthermore, there is a relatively large gap between star 2 and star 3. This phenomenon shows that emotion trend has the ability to distinguish star ratings, especially when a review seems to be neutral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"image/root_slope.png\" width = \"400\" height = \"200\" alt=\"2-step model\" align=center />\n",
       "<h6 align=\"center\"> Fig. 7.Boxplot of emotion trend under each star rating</h6> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"image/root_slope.png\" width = \"400\" height = \"200\" alt=\"2-step model\" align=center />\n",
    "<h6 align=\"center\"> Fig. 7.Boxplot of emotion trend under each star rating</h6> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Modeling\n",
    "\n",
    "#### 4.1 Model by extracted features\n",
    "Now we have four extracted features for model building. We find that minimum score, average score and maximum score has cubed relationship with star rating. Hence we add the value of second and third order power of them.\n",
    "\n",
    "To get an interpretable model, we choose classification and regression tree model for this part. The fitted model can be represented as the figure below. For example, if a review has average score less than -0.1, squared  average score greater than 1.1 and squared minimum score greater than 5.8, then the fitted star rating is 1.2.\n",
    "\n",
    "Every node in the tree uses the feature which could split the reviews in the way that star ratings of the two groups are farthest apart. For example, the average score can best distinguish different star ratings at the first node which split the reviews into positive and negative groups. In both groups, average score continues to play a role in the second node. After that, the maximum score begins to work, measuring how positive a review is. Meanwhile, the minimum score is measuring how negative a review is. Whereas the slope begins to work when a review seems to be neutral based on other three features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"image/tree.png\" width = \"700\" height = \"300\" alt=\"2-step model\" align=center />\n",
       "<h6 align=\"center\"> Fig. 8.Regression tree of star rating </h6> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"image/tree.png\" width = \"700\" height = \"300\" alt=\"2-step model\" align=center />\n",
    "<h6 align=\"center\"> Fig. 8.Regression tree of star rating </h6> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Bag of Words Model\n",
    "\n",
    "In order to predict the star ratings more accurately, we tried some machine learning methods using sparse matrix, where the i-th row represents the i-th review, and the j-th column represents the j-th token. The (i,j)-entry of this matrix represents the tf-idf quantity of the j-th token in the i-th review.\n",
    "\n",
    "After several tries, we find it more accurate to consider both one single word and two pairwise words in the model fitting. For example: **I like it** is transformed into **i**, **like**, **it**, **i like** and **like it**.\n",
    "\n",
    "The initial thought is to build a one-step model directly using Support Vector Classifier, Linear Regression and Naive Bayes. Study in a deep-going way, we tried to first divide the star rating into positive rating(3-5 stars) and negative rating(1-2 star(s)), and build two separate models. This is how our 2-step models build:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"image/2stepmodel.png\" width = \"300\" height = \"200\" alt=\"2-step model\" align=center />\n",
       "<h6 align=\"center\"> Fig. 9. Two-step model procedure</h6> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"image/2stepmodel.png\" width = \"300\" height = \"200\" alt=\"2-step model\" align=center />\n",
    "<h6 align=\"center\"> Fig. 9. Two-step model procedure</h6> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supprt Vector Classifier is a useful way in binary classification of negtive and positive reviews, which achiecves an accuracy around 90%. Here we compare several models:\n",
    "\n",
    "|       | Model | RMSE |\n",
    "| ------| ------ | ------ |\n",
    "| 1-step model | SVC | 0.75 |\n",
    "| 1-step model | NB | 0.84 |\n",
    "| 2-step model | SVC+SVC | 0.716 |\n",
    "| 2-step model | **SVC+Linear** | **0.665** |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Conclusion\n",
    "\n",
    "#### 5.1 Thesis Statement\n",
    "* Words with sentiment orientation play a key role in predicting star ratings.\n",
    "* It is easier to distinguish positive (3-5 stars) reviews from negative ones (1-2 star(s)) than telling the specific star rating.\n",
    "\n",
    "#### 5.2 Strengths and Weaknesses\n",
    "\n",
    "In this section we analyze our strengths and weaknesses during the whole analysis procedure.\n",
    "\n",
    "**Pros: ** \n",
    "* Take context into consideration\n",
    "* Balanced the star distribution        \n",
    "* The features are easy to interprete\n",
    "* Get more insight of how review text contributes to its star rating\n",
    "* Good performance on test data \n",
    "* Time efficient: about 10 min per running round\n",
    "              \n",
    "**Cons: ** \n",
    "* May lose information due to limited sample size\n",
    "* For decision tree model: not accurate, without consideration of higher order interaction\n",
    "* Some violation of assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Division of work\n",
    "* Guanxu Su: Data Preprocessing; Text Cleaning; Feature Extraction\n",
    "* Shurong Gu: Model Building; Final Kaggle Prediction\n",
    "* Yuwei Sun: Parameter Optimization; Presentation Organization"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
